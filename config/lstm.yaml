

model:
  name: "LSTM"
  type: "sequence_forecasting"
  input_size: 8
  hidden_size: 64
  num_layers: 2
  dropout: 0.2
  bidirectional: false
  output_size: 1
  activation: "relu"

data:
  target: "CO(GT)"
  lookback: 24
  horizon: 1
  batch_size: 32
  shuffle: false
  normalize: true

training:
  epochs: 50
  learning_rate: 0.001
  optimizer: "adam"
  loss_fn: "mse"
  scheduler: true
  early_stopping: true
  patience: 5
  gradient_clip: 1.0
  save_best_only: true
  model_save_name: "lstm_best.pt"

evaluation:
  metrics: ["MAE", "RMSE", "R2"]
  visualize_predictions: true
  plot_loss_curve: true
